{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20297477-f00a-4ba3-990f-19dabe926e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado final: ejemplo texto contien caracter especial n mero palabra may scula queremo preprocesar texto est listo an lisi texto proyecto procesamiento lenguaj natur nlp\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer  \n",
    "from langdetect import detect\n",
    "\n",
    "# Texto de entrada\n",
    "texto = \"\"\"Este es un ejemplo de texto que contiene algunos caracteres especiales, números y palabras en mayúsculas. \n",
    "Queremos preprocesar este texto para que esté listo para el análisis de texto en un proyecto de Procesamiento de Lenguaje Natural (NLP).\"\"\"\n",
    "# 1. Eliminación de caracteres especiales y números\n",
    "texto_limpio =  re.sub(r'[^a-zA-Z]', ' ', texto)\n",
    "\n",
    "# 2. Conversión a minúsculas\n",
    "texto_limpio = texto_limpio.lower()\n",
    "\n",
    "# 3. Tokenización\n",
    "tokens = word_tokenize(texto_limpio)  \n",
    "\n",
    "# 4. Eliminación de stopwords\n",
    "stop_words = set(stopwords.words('spanish'))  # Usa stopwords en español\n",
    "tokens_filtrados = [palabra for palabra in tokens if palabra not in stop_words]\n",
    "\n",
    "# 5. Stemming (Para reducir las palabras a su raíz o forma base) \n",
    "stemmer = PorterStemmer()  # Usando PorterStemmer para español\n",
    "tokens_stemmed = [stemmer.stem(palabra) for palabra in tokens_filtrados]\n",
    "\n",
    "# Resultado final\n",
    "resultado = ' '.join(tokens_stemmed)\n",
    "print(\"Resultado final:\", resultado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4da68d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecddad66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m472.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langdetect) (1.16.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=25e202a1fb112647ba7bde38d4a2d985d3c8929ef4c325a2af8783bb7902dac8\n",
      "  Stored in directory: /Users/hectorsosa/Library/Caches/pip/wheels/c1/67/88/e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langdetect"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
